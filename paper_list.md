### ğŸ¤– æ™ºèƒ½ä½“ (Agentic AI)

* [ ] [ToolACE: Winning the Point](https://www.google.com/search?q=Agent/2471_ToolACE_Winning_the_Point.pdf)
* [ ] [Agentic Retrieval-Augmented Generation: A Survey](https://www.google.com/search?q=Agent/AGENTIC%2520RETRIEVAL-AUGMENTED%2520GENERATION%2520A%2520SURVEY%2520ON.pdf)
* [ ] [Facilitating Multi-turn Function Calling](https://www.google.com/search?q=Agent/FACILITATING%2520MULTI-TURN%2520FUNCTION%2520CALLING%2520FOR.pdf)
* [ ] [FinRegLab: The Next Wave Arrives](https://www.google.com/search?q=Agent/FinRegLab_09-04-2025_The-Next-Wave-Arrives-Main.pdf)

### ğŸ› ï¸ å¤§æ¨¡å‹å¾®è°ƒä¸å¯¹é½ (LLM + SFT)

* [ ] [DeepSeek-R1: Incentivizing Reasoning Capability via RL](https://www.google.com/search?q=LLM%2BSFT/DeepSeek-R1%2520Incentivizing%2520Reasoning%2520Capability%2520in%2520LLMs%2520via.pdf) â€” *é‡ç‚¹å…³æ³¨æ¨ç†èƒ½åŠ›æå‡*
* [ ] [LoRA: Low-Rank Adaptation of Large Language Models](https://www.google.com/search?q=LLM%2BSFT/LoRA%2520Low-Rank%2520Adaptation%2520of.pdf)
* [ ] [QLoRA: Efficient Finetuning of Quantized LLMs](https://www.google.com/search?q=LLM%2BSFT/NeurIPS-2023-qlora-efficient-finetuning-of-quantized-llms-Paper-Conference.pdf)
* [ ] [LIMA: Less Is More for Alignment](https://www.google.com/search?q=LLM%2BSFT/NeurIPS-2023-lima-less-is-more-for-alignment-Paper-Conference.pdf)
* [ ] [InstructGPT: Training Language Models to Follow Instructions](https://www.google.com/search?q=LLM%2BSFT/NeurIPS-2022-training-language-models-to-follow-instructions-with-human-feedback-Paper-Conference.pdf)
* [ ] [Artificial Hivemind: The Open-Ended Homogeneity
of Language Models (and Beyond)](https://www.google.com/search?q=LLM%2BSFT/Artificial_Hivemind_The_O.pdf)

### âœï¸ æç¤ºå·¥ç¨‹ (Prompt Engineering)

* [ ] Language Models are Few-Shot Learners
* [ ] The Prompt Report
* [ ] Chain-of-Thought (CoT) Prompting
* [ ] Tree of Thoughts: Deliberate Problem Solving
* [ ] ReAct: Synergizing Reasoning and Acting
* [ ] System 2 Attention (S2A)

### ğŸ’° è¡Œä¸šåº”ç”¨ä¸åˆ†äº« (Financial & Research)

* [x] **[Financial Analyst Report Comprehension (Gemini 2.5/o3/Grok 4)](https://www.google.com/search?q=Sharing1.20/Can%2520AI%2520Read%2520Like%2520a%2520Financial%2520Analyst%2520A%2520Financial%2520Touchstone%2520for%2520Frontier%2520Language%2520Models%2520such%2520as%2520Gemini%25202.5%2520Pro,%2520o3,%2520and%2520Grok%25204%2520on%2520Long-Context%2520Annual%2520Report%2520Comprehension.pdf)** â€” *å·²å®ŒæˆæŠ€æœ¯åˆ†äº«æŠ¥å‘Š*
* [ ] [A Multi-Agent Framework for Financial Analysis](https://www.google.com/search?q=Sharing1.20/26_A_Multi_Agent_Framework_for.pdf)
* [x] [GraphRAG: From Local to Global](https://www.google.com/search?q=Sharing1.20/From%2520Local%2520to%2520Global%2520A%2520GraphRAG%2520Approach%2520to.pdf)
* [ ] [LEANN: A Low-Storage Overhead Vector Index](https://www.google.com/search?q=Sharing1.20/LEANN%2520A%2520LOW-STORAGE%2520OVERHEAD%2520VECTOR%2520INDEX.pdf)

### ğŸ“¡ å…¶ä»–ä¸“é¡¹ (Special Topics)

* [x] **é€šä¿¡**ï¼š[Waveform Design for Integrated VLPC](https://www.google.com/search?q=telecomunication/Waveform_Design_and_Optimization_for_Integrated_Visible_Light_Positioning_and_Communication.pdf) â€” *éœ€å‡†å¤‡æ•™å­¦æ±‡æŠ¥*
* [ ] **ä¼ ç»Ÿæœºå™¨å­¦ä¹ **ï¼š[XGBoost: A Scalable Tree Boosting System](https://www.google.com/search?q=Traditional%2520Machine%2520Learning/XGBoost%2520A%2520Scalable%2520Tree%2520Boosting%2520System.pdf) â€” *ç»“åˆå½“å‰æ¨èä»»åŠ¡å¤ä¹ *

